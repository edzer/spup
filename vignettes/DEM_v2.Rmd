---
title: "Spatial uncertainty propagation analysis"
author: "Kasia Sawicka and Gerard Heuvelink"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
# output: rmarkdown::word_document
subtitle: Case study with spatially variable standard deviation - slope calculations
  with a digital elevation model (DEM)
vignette: >
  %\VignetteIndexEntry{Spatial uncertainty propagation analysis}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---


```{r, echo = FALSE}
knitr::opts_chunk$set(
    comment = NA,
    quiet = TRUE,
    progress = FALSE,
    tidy = FALSE,
    cache = FALSE,
    message = FALSE,
    error = FALSE, # FALSE: always stop execution.
    warning = TRUE,
    dpi = 100
)
```

```{r, echo = FALSE}
knitr::opts_knit$set(global.par = TRUE)
```

```{r, echo = FALSE}
par(mar = c(3, 3, 2, 2), mgp = c(1.7, 0.5, 0), las = 1, cex.main = 1, tcl = -0.2, cex.axis = 0.8,
    cex.lab = 0.8)
```


### Introduction/Problem definition

In many geographical studies a DEM is a critical variable, because DEM-derived variables such as slope and aspect, curvature and viewshed are of great importance in many types of analysis. However, the DEM is only an approximation of the real elevation in the area. It contains errors. Insight into the DEM error, uncertainty, and its propagation through the calculation of, for example, slope, is therefore crucial. We can use the Monte Carlo (MC) method to analyse how the error propagates through spatial operations and models. This method is briefly decribed below. 

The MC method is fairly straightforward in application, but in case of spatially distributed variables like elevation one should consider taking spatial autocorrelation into account. That is because the model output may be influenced by the spatial correlation in the input. For example, slope calculations are quite sensitive to the degree of spatial autocorrelation in the DEM errors (Heuvelink, 1998). 

<br>

### Adapted Monte Carlo methodology for spatial uncertainty analysis with spatially variable sd

The adapted uncertainty propagation analysis approach is based on the Monte Carlo method that computes the output of the model repeatedly, with input values that are randomly sampled from their marginal or joint pdf. The set of model outputs forms a random sample from the output pdf, so that the parameters of the distribution, such as the mean, variance and quantiles, can be estimated from the sample. The method thus consists of the following steps:

1.	Characterise uncertain model inputs with pdfs.
1.	Repeatedly sample from (spatial) pdfs of uncertain inputs.
1.	Run model with sampled inputs and store model outputs.
1. 	Compute summary statistics of model outputs.

Note that the above ignores uncertainty in model parameters and model structure, but these can easily be included if available as probability distribution functions (pdfs). A random sample from the model inputs can be obtained using an appropriate pseudo-random number generator. 

For uncertain spatially distributed continuous variables, such as elevation, rainfall and soil organic carbon content, we assume the following geostatistical model:

	Z(x)= μ(x)+ σ(x)∙ε(x)

where x is geographic location,  μ is the (deterministic) mean of Z, σ is its standard deviation and ε is a standard normal, second-order stationary stochastic residual, whose spatial autocorrelation is  modelled with a semivariogram or correlogram. Note that ε has zero mean and unit variance. However, both μ and σ may vary in space so that spatial trends and spatially variable uncertainty can be taken into account. In the case of elevation, it makes sense to let μ be equal to the DEM while σ may have greater values in mountainous areas than in flat terrain (Beekhuizen, et al., 2011). The random sample is drawn from the pdf of ε to further calculate a sample from Z.

<br>

### DEM uncertainty propagation analysis with 'spup'

<br>

#### Preliminaries - load and view the data

The example data for slope calculations are a 30m resolution mean DEM and standard deviation from the Zlatibor region in Serbia.

The 'DEM' data contains two spatial objects: a mean DEM of the area and the standard deviation. It also has a saved function that calculates slope from DEM that will be used later.


```{r, fig.width = 5, fig.height = 3} 
# load packages
library(sp)
library(spup)

# load and view the data
data(DEM)
str(dem30m)
str(dem30m_sd)
spplot(dem30m, main = list(label = "Mean DEM", cex = 1))
summary(dem30m_sd)
```

<br>

#### Define uncertainty model (UM) for the DEM

The first step in uncertainty propagation analysis is to define an uncertainty model for the uncertain input variable, here elevation, that will be used in the Monte Carlo uncertainty propagation analysis. 

In case of elevation, the ε(x) are spatially correlated and in order to include this in the analysis, we need to describe it by spatial correlogram parameters. The `makecrm()` function collates all necessary information into a list.

Let us assume that the spatial autocorrelation of the DEM errors is an exponentially decreasing function with a short-distance correlation of 0.8 and a range parameter of 300m.

<br>

```{r} 
# define spatial correlogram model
dem_crm <- makecrm(acf0 = 0.8, range = 300, model = "Exp")
```

We can view the correlogram by plotting it.

```{r, fig.width = 5, fig.height = 3} 
plot(dem_crm, main = "DEM correlogram")
```

Spatial correlograms summarise patterns of spatial autocorrelation in data and model residuals. They show the degree of correlation between values at two locations as a function of the separation distance between the locations. In the case above the correlation declines with distance, as is usually the case. The correlation becomes negligibly small for distances greater than 800 m. Notice also that the correlation is not perfect at distances close to zero. This signifies the so-called ‘nugget’ effect. You can manipulate the nugget effect, the shape of the correlation function and the maximum range by changing the parameters of the `makecrm()` function. Try, for example, these combinations and see how they look like:

```{r, fig.width = 7, fig.height = 5} 
par(mfrow = c(2, 2))
crm <- makecrm(acf0 = 0.8, range = 700, model = "Sph") 
plot(crm, main = "'Spherical', acf0 = 0.8, range = 700")
crm <- makecrm(acf0 = 0.2, range = 700, model = "Sph") 
plot(crm, main = "'Spherical', acf0 = 0.2, range = 700")
crm <- makecrm(acf0 = 0.8, range = 700, model = "Lin") 
plot(crm, main = "'Linear', acf0 = 1.0, range = 700")
crm <- makecrm(acf0 = 0.8, range = 200, model = "Gau") 
plot(crm, main = "'Gausian', acf0 = 0.8, range = 200")
```


In order to complete the description of the uncertain variable we use the `defineUM()` function that collates all information about the DEM uncertainty into one object. The minimum information required is:

* a logical value that indicates if the object is uncertain.
* the type of the distribution to sample from. In case of variables with spatially correlated errors only the normal distribution is supported. For details on supported distributions and required parameters see `?defineUM`.
* the list of distribution parameters, for example a mean and a standard deviation (sd) for the normal distribution. In the case presented here, these are maps of the mean DEM and standard deviation of the DEM error. 
* correlogram model.


```{r} 
# define uncertainty model for the DEM
demUM <- defineUM(uncertain = TRUE, distribution = "norm", 
                   distr_param = c(dem30m, dem30m_sd), crm = dem_crm)
class(demUM)
```

<br>

#### Generate possible realities of DEM

Generating possible realities of the DEM can be completed by using the genSample() function. The required information to pass to the function includes:

* defined uncertain object (as above).
* number of realizations to return.
* sampling method. In case of spatially correlated variables, the method "ugs" (method based on unconditional gaussian simulation) is reccomended, otherwise spatial correlation will not be taken into account. Other sampling methods include "randomSampling" and "stratifiedSampling". See `?genSample` for more details.

Additional parameters may be also specified. For example, sampling of spatially correlated variable is based on the 'gstat' package that allows for limiting the number of nearest observations that should be used for the simulation.

Usually the sample must be large to obtain stable results. Let us run the sampling to obtain 100 realizations. Note the artument 'asList' has been set up to FALSE. This indicates that the sampling function will return an object of a class of the distribution parameters class. This is useful if you want to visualize the sample or compute summary statistics quickly.

```{r, fig.width = 7, fig.height = 7} 
# create possible realizations of the DEM
dem_sample <- genSample(UMobject = demUM, n = 100, samplemethod = "ugs", nmax = 20, asList = FALSE)

# view several realizations of DEM
spplot(dem_sample[c(5,6,3,4,1,2)], main = list(label = "Examples of the slope realizations", cex = 1))
```

We can view the mean and standard deviation of the sampled DEM. If the number of samples was very large then the mean of the sample would equal dem30m and the sd would equal dem30m_sd:

```{r, fig.width = 5, fig.height = 6}
# compute and plot the slope sample statistics
# e.g. mean and standard deviation
dem_sample_mean <- mean(dem_sample)
dem_sample_sd <- sd(dem_sample)
m <- spplot(dem_sample_mean, main = list(label = "Mean of the DEM realizations", cex = 1))
s <- spplot(dem_sample_sd, main = list(label = "Standard dev. of the DEM realizations", cex = 1))
print(m, split = c(1, 1, 1, 2), more = TRUE)
print(s, split = c(1, 2, 1, 2))
rm(m, s)
```

The generated DEM realizations depend on the degree of spatial auto-correlation. For instance, notice that the realizatons become more ‘noisy’ if we assume less spatial-autocorrelation:

```{r, fig.width = 5, fig.height = 6} 
dem_crm2 <- makecrm(acf0 = 0.2, range = 300, model = "Exp")
demUM2 <- defineUM(uncertain = TRUE, distribution = "norm", distr_param = c(dem30m, dem30m_sd), crm = dem_crm2)
dem_sample2 <- genSample(UMobject = demUM2, n = 100, samplemethod = "ugs", nmax = 20, asList = FALSE)
s1 <- spplot(dem_sample, c(1), main = list(label = "dem_sample, acf0 = 0.8, range = 300m", cex = 1))
s2 <- spplot(dem_sample2, c(1), main = list(label = "dem_sample2, acf0 = 0.2, range = 300m", cex = 1))
print(s1, split = c(1, 1, 1, 2), more = TRUE)
print(s2, split = c(1, 2, 1, 2))
rm(s1, s2)
```

Can you spot the difference? Higher auto-correlation yields ‘smoothened’ realities. Lower values produce a more ‘noisy’ field.

#### Uncertainty propagation through the model that calculates slope using DEM as input

In order to perform uncertainty propagation analysis using 'spup', the model through which uncertainty is propagated needs to be defined as an R function. The 'DEM' data object includes an example of a pre-defined model that calculates slope using DEM as input. In this case the function is based on the `terrain()` function from the **raster** package. 

```{r} 
# view the model
Slope
```

The propagation of uncertainty occurs when the model is run with an uncertain input. Running the model with a sample of realizations of uncertain input variable(s) yields an equally large sample of model outputs that can be further analyzed. To run the Slope model with the DEM realizations we use the `propagate()` function. The `propagate()` function takes as arguments:

* a sample from the uncertain model inputs and any other remaining model inputs and parameters as a list.
* the model as a function in R.
* the number of Monte Carlo runs. This can be equal or smaller than the number of realizations of the uncertain input variable(s).

In order to run the propagation function the sample of an uncertain input variable must be saved in a list. We can either coerce the existing **dem_sample** object or get it automatically setting up the 'asList' argument of `genSample()` to TRUE.

```{r} 
# coerce  SpatialGridDataFrame to a list of individual SpatialGridDataFrames
dem_sample <- map(1:ncol(dem_sample), function(x){dem_sample[x]})

# or sample from uncertain input and save it in a list
dem_sample <- genSample(UMobject = demUM, n = 100, samplemethod = "ugs", nmax = 20, asList = TRUE)
```

```{r} 
# run uncertainty propagation
slope_sample <- propagate(dem_sample, model = Slope, n = 100, projection = CRS("+init=epsg:3857"))
```

<br>

#### Visualization of results

We can now view the sample of model output realizations (i.e. slope) and visualize uncertainty by calculating and plotting the sample mean and standard deviation. In our case we need to coerce the output of the `propagation`function saved as a list back to a SpatialGridDataFrame. 


```{r, fig.width = 7, fig.height = 7} 
# coerce slopes list to a SpatialGridDataFrame
s <- slope_sample[[1]]
for (i in 2:length(slope_sample)) {
  s@data[i] <- slope_sample[[i]]@data
}
names(s@data) <- paste("slope", c(1:ncol(s)), sep = "")
slope_sample <- s
rm(s)

# view the sample of the model output
spplot(slope_sample[c(5,6,3,4,1,2)], main = list(label = "Examples of the slope realizations", cex = 1))
```

```{r, fig.width = 5, fig.height = 6}
# compute and plot the slope sample statistics
# e.g. mean and standard deviation
slope_mean <- mean(slope_sample)
slope_sd <- sd(slope_sample, na.rm = TRUE) # na.rm = TRUE is necessary, because slope cannot be calculated at the border
m <- spplot(slope_mean, main = list(label = "Mean of the slope realizations", cex = 1))
s <- spplot(slope_sd, main = list(label = "Standard dev. of the slope realizations", cex = 1))
print(m, split = c(1, 1, 1, 2), more = TRUE)
print(s, split = c(1, 2, 1, 2))
rm(m, s)
```

We can see from the maps that lower slopes are observed at lower elevation and higher slopes at elevation. Since we used the roughness of the terrain as DEM sd approximation, the slope sd corresponds with the DEM sd. We can view example of slope realizations at locations with low and high elevation:

```{r, fig.width = 7, fig.height = 3}
# check the histogram of slope at lowest and highest DEM 
l <- which(dem30m@data == min(dem30m@data)) # there is no slope calculated for this outer value so we need to fins a different one
l <- which(dem30m@data < 860)
l
# lets take location 400 for l.
h <- which(dem30m@data == max(dem30m@data))
h
l_mean <- mean(as.numeric(slope_sample@data[400,]))
l_sd <- sd(as.numeric(slope_sample@data[400,]))
h_mean <- mean(as.numeric(slope_sample@data[6898,]))
h_sd <- sd(as.numeric(slope_sample@data[6898,]))

par(mfrow = c(1,2))
hist(as.numeric(slope_sample@data[400,]), main = paste("Slope at low DEM,", "\n",
     "mean = ", round(l_mean, 2), ", sd = ", round(l_sd, 2), sep = ""), xlab = "Slope")
hist(as.numeric(slope_sample@data[6898,]), main = paste("Slope at high DEM,", "\n",
     "mean = ", round(h_mean, 2), ", sd = ", round(h_sd, 2), sep = ""), xlab = "Slope")
rm(l, h)
```

Here interpretation of histograms - KS: Why do we have higher slope at lower DEM/ Is this correct?

We can also look at specific quantites of the slope sample. 

```{r, fig.width = 7, fig.height = 5}
# or quantiles
slope_q <- quantile(slope_sample, probs = c(0.1, 0.25, 0.75, 0.9), na.rm = TRUE)
spplot(slope_q[c(3,4,1,2)], mail = list(label = "Quantiles of slope realizations", cex = 1))
```

For example, find locations with steep slopes that are safe (slope < 0.5) for tourist skiing with probability 90%.

```{r, fig.width = 5, fig.height = 3}
slope_q$safep90 <- factor(ifelse(slope_q$prob90perc > 0.5, 1, 0), labels = c("safe","hazard"))
spplot(slope_q, "safep90", col.regions = c("green","red"), main = "Safe areas for skiing")
```
<br>



### Acknowledgements

The Zlatibor dataset was kindly provided by Prof. Branislav Bajat from the University of Belgrade, Serbia. 

This project has received funding from the European Union’s Seventh Framework Programme for research, technological development and demonstration under grant agreement no 607000.

### References

Beekhuizen, J. G.B.M. Heuvelink, J. Biesemans and I. Reusen (2011), Effect of DEM uncertainty on the positional accuracy of airborne imagery. IEEE Transactions on Geoscience and Remote Sensing 49, 1567 1577.